{
  "210": {
    "inputs": {
      "ckpt_name": "sd_xl_base_1.0.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "211": {
    "inputs": {
      "vae_name": "sdxl_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "219": {
    "inputs": {
      "seed": 156680208700285
    },
    "class_type": "Seed",
    "_meta": {
      "title": "Seed"
    }
  },
  "221": {
    "inputs": {
      "width": 1344,
      "height": 768,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "223": {
    "inputs": {
      "text": "((a young German woman standing next to a BMW M4 Race car on a German road, desolate road )), (long exposure photo:1.4), (vibrant sky:1.4), (silhouetted subject:1.2), (high contrast:1.2), dynamic composition, high detail, natural light, expressive, ethereal, atmospheric, moody, dramatic, deep shadows, soft highlights, rich colors, glowing reflections, textured, expansive, mesmerizing, bold, surreal, dreamlike, powerful, captivating, 24mm lens, f/8, evocative, enchanting, majestic",
      "clip": [
        "210",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "224": {
    "inputs": {
      "text": "park, trees,(low quality, low detail, bw, bad photo, bad photography,poorly lit, bad shadow,:1.4),(painting, drawing, sketch, cartoon, anime, manga, render, CG, 3d, cartoon,airbrushed, cgi, render, blender, digital art, amateur:1.3),(bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities,disfigured,ugly, mutated, malformed, mutilated,missing fingers,ugly nails,:1.2), text, watermark ",
      "clip": [
        "210",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "232": {
    "inputs": {
      "strength": 0.25,
      "start_percent": 0,
      "end_percent": 0.5,
      "positive": [
        "223",
        0
      ],
      "negative": [
        "224",
        0
      ],
      "control_net": [
        "233",
        0
      ],
      "image": [
        "247",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "233": {
    "inputs": {
      "control_net_name": "Union\\controlnet-union-sdxl-1.0.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "234": {
    "inputs": {
      "images": [
        "247",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "236": {
    "inputs": {
      "image": "untitled (1).png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "247": {
    "inputs": {
      "preprocessor": "DepthAnythingPreprocessor",
      "resolution": 768,
      "image": [
        "236",
        0
      ]
    },
    "class_type": "AIO_Preprocessor",
    "_meta": {
      "title": "AIO Aux Preprocessor"
    }
  },
  "248": {
    "inputs": {
      "strength": 0.25,
      "start_percent": 0,
      "end_percent": 0.5,
      "positive": [
        "232",
        0
      ],
      "negative": [
        "232",
        1
      ],
      "control_net": [
        "249",
        0
      ],
      "image": [
        "252",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "249": {
    "inputs": {
      "control_net_name": "Union\\controlnet-union-sdxl-1.0.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "250": {
    "inputs": {
      "images": [
        "252",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "251": {
    "inputs": {
      "image": "untitled (1).png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "252": {
    "inputs": {
      "preprocessor": "OpenposePreprocessor",
      "resolution": 768,
      "image": [
        "251",
        0
      ]
    },
    "class_type": "AIO_Preprocessor",
    "_meta": {
      "title": "AIO Aux Preprocessor"
    }
  },
  "253": {
    "inputs": {
      "strength": 0.25,
      "start_percent": 0,
      "end_percent": 0.5,
      "positive": [
        "248",
        0
      ],
      "negative": [
        "248",
        1
      ],
      "control_net": [
        "254",
        0
      ],
      "image": [
        "257",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "254": {
    "inputs": {
      "control_net_name": "Union\\controlnet-union-sdxl-1.0.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "255": {
    "inputs": {
      "images": [
        "257",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "256": {
    "inputs": {
      "image": "untitled (1).png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "257": {
    "inputs": {
      "preprocessor": "CannyEdgePreprocessor",
      "resolution": 768,
      "image": [
        "256",
        0
      ]
    },
    "class_type": "AIO_Preprocessor",
    "_meta": {
      "title": "AIO Aux Preprocessor"
    }
  },
  "258": {
    "inputs": {
      "strength": 0.3,
      "start_percent": 0,
      "end_percent": 0.5,
      "positive": [
        "253",
        0
      ],
      "negative": [
        "253",
        1
      ],
      "control_net": [
        "259",
        0
      ],
      "image": [
        "262",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "259": {
    "inputs": {
      "control_net_name": "Union\\controlnet-union-sdxl-1.0.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "260": {
    "inputs": {
      "images": [
        "262",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "261": {
    "inputs": {
      "image": "untitled (1).png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "262": {
    "inputs": {
      "preprocessor": "DSINE-NormalMapPreprocessor",
      "resolution": 768,
      "image": [
        "261",
        0
      ]
    },
    "class_type": "AIO_Preprocessor",
    "_meta": {
      "title": "AIO Aux Preprocessor"
    }
  },
  "278": {
    "inputs": {
      "preset": "VIT-G (medium strength)",
      "model": [
        "210",
        0
      ]
    },
    "class_type": "IPAdapterUnifiedLoader",
    "_meta": {
      "title": "IPAdapter Unified Loader"
    }
  },
  "288": {
    "inputs": {
      "samples": [
        "560",
        0
      ],
      "vae": [
        "211",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "400": {
    "inputs": {
      "filename_prefix": "MediaMonks_AllTheGoodThings-Generation-v1.9-FirstPass",
      "images": [
        "288",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "493": {
    "inputs": {
      "text": "cinematic still wide front angle shot of a BMW M4 Car with detailed grille <br>\ncinematic still, wide shot, young German woman wearing a RED sweater and jeans, short hair, candid expression, freckles, skin pores, ultra-detailed skin <br>\ngerman road <br>\namazing sky\n\n",
      "line_break": "<br>",
      "clip": [
        "210",
        1
      ]
    },
    "class_type": "CLIPTextEncode|MediaMonks",
    "_meta": {
      "title": "Multiprompt - Clip Text Encode"
    }
  },
  "494": {
    "inputs": {
      "model": [
        "542",
        0
      ],
      "base_mask": [
        "500",
        0
      ],
      "masks": [
        "495",
        0
      ],
      "conds": [
        "493",
        0
      ]
    },
    "class_type": "AttentionCouple|MediaMonks",
    "_meta": {
      "title": "Attention Couple"
    }
  },
  "495": {
    "inputs": {
      "invert": false,
      "multi_masks_from_single_image": true,
      "colors": "1:(255,0,0),10\n2:(0,255,0),10\n3:(255,255,255),10\n4:(0,255,0),10\n\n",
      "per_batch": 16,
      "image_1": [
        "498",
        0
      ]
    },
    "class_type": "ColorPromptToMask|MediaMonks",
    "_meta": {
      "title": "Color Prompt To Mask"
    }
  },
  "498": {
    "inputs": {
      "image": "untitled1 (3).png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "499": {
    "inputs": {
      "images": [
        "501",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "500": {
    "inputs": {
      "value": 1,
      "width": 1344,
      "height": 768
    },
    "class_type": "SolidMask",
    "_meta": {
      "title": "SolidMask"
    }
  },
  "501": {
    "inputs": {
      "mask": [
        "500",
        0
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "541": {
    "inputs": {
      "image": "mjip4.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "542": {
    "inputs": {
      "weight": 0.5,
      "weight_faceidv2": 0,
      "weight_type": "style transfer precise",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "layer_weights": "3:2.6, 6:1",
      "model": [
        "278",
        0
      ],
      "ipadapter": [
        "278",
        1
      ],
      "image": [
        "541",
        0
      ]
    },
    "class_type": "IPAdapterMS",
    "_meta": {
      "title": "IPAdapter Mad Scientist"
    }
  },
  "560": {
    "inputs": {
      "samples": [
        "569",
        0
      ]
    },
    "class_type": "gcLatentTunnel",
    "_meta": {
      "title": "LatentGarbageCollector"
    }
  },
  "569": {
    "inputs": {
      "seed": [
        "219",
        3
      ],
      "steps": 50,
      "cfg": 5,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "494",
        0
      ],
      "positive": [
        "258",
        0
      ],
      "negative": [
        "258",
        1
      ],
      "latent_image": [
        "221",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "591": {
    "inputs": {
      "text": [
        "600",
        0
      ],
      "clip": [
        "616",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "592": {
    "inputs": {
      "vae_name": "ae.sft"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "593": {
    "inputs": {
      "clip_name1": "t5xxl_fp8_e4m3fn.safetensors",
      "clip_name2": "clip_l.safetensors",
      "type": "flux"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "594": {
    "inputs": {
      "unet_name": "flux1-dev.safetensors",
      "weight_dtype": "fp8_e4m3fn"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "595": {
    "inputs": {
      "noise": [
        "599",
        0
      ],
      "guider": [
        "598",
        0
      ],
      "sampler": [
        "596",
        0
      ],
      "sigmas": [
        "597",
        0
      ],
      "latent_image": [
        "635",
        0
      ]
    },
    "class_type": "SamplerCustomAdvanced",
    "_meta": {
      "title": "SamplerCustomAdvanced"
    }
  },
  "596": {
    "inputs": {
      "sampler_name": "euler"
    },
    "class_type": "KSamplerSelect",
    "_meta": {
      "title": "KSamplerSelect"
    }
  },
  "597": {
    "inputs": {
      "scheduler": "simple",
      "steps": 40,
      "denoise": 1,
      "model": [
        "602",
        0
      ]
    },
    "class_type": "BasicScheduler",
    "_meta": {
      "title": "BasicScheduler"
    }
  },
  "598": {
    "inputs": {
      "model": [
        "602",
        0
      ],
      "conditioning": [
        "601",
        0
      ]
    },
    "class_type": "BasicGuider",
    "_meta": {
      "title": "BasicGuider"
    }
  },
  "599": {
    "inputs": {
      "noise_seed": 298347309747023
    },
    "class_type": "RandomNoise",
    "_meta": {
      "title": "RandomNoise"
    }
  },
  "600": {
    "inputs": {
      "string": "Amateur boring photograph of a young handsome italian-argentinian 35 year old man with short curly hair standing next to a motorcycle a Military aviation runway. The motorcycle BLACK Yamaha MT09 with the number \"09\" on the side. The man is wearing a jean jacket, black jeans, and white sneakers. He has a tattoo on his left arm and is holding the handlebars of the motorcycle. The bike has a sleek and modern design with a low-slung frame and a large fuel tank. The background is a military airport, but it appears to be a sunset, perfect eyes, clear brown eyes, front facing portrait, TOP GUN STYLE,"
    },
    "class_type": "String Literal",
    "_meta": {
      "title": "String Literal"
    }
  },
  "601": {
    "inputs": {
      "guidance": 4,
      "conditioning": [
        "591",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "602": {
    "inputs": {
      "max_shift": 0.5,
      "base_shift": 0.5,
      "width": [
        "637",
        0
      ],
      "height": [
        "637",
        1
      ],
      "model": [
        "616",
        0
      ]
    },
    "class_type": "ModelSamplingFlux",
    "_meta": {
      "title": "ModelSamplingFlux"
    }
  },
  "605": {
    "inputs": {
      "samples": [
        "595",
        0
      ],
      "vae": [
        "592",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "606": {
    "inputs": {
      "images": [
        "605",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "611": {
    "inputs": {
      "filename_prefix": "AnalogFLux/Anal_",
      "images": [
        "613",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "612": {
    "inputs": {
      "intensity": 0.09,
      "scale": 100,
      "temperature": 0,
      "vignette": 0,
      "image": [
        "620",
        0
      ]
    },
    "class_type": "FilmGrain",
    "_meta": {
      "title": "Film Grain Effect"
    }
  },
  "613": {
    "inputs": {
      "lut_file": "Presetpro - Kodachrome.cube",
      "gamma_correction": true,
      "clip_values": true,
      "strength": 0.30000000000000004,
      "image": [
        "612",
        0
      ]
    },
    "class_type": "ImageApplyLUT+",
    "_meta": {
      "title": "🔧 Image Apply LUT"
    }
  },
  "614": {
    "inputs": {
      "mode": "bilinear",
      "factor": 1.05,
      "align": "true",
      "samples": [
        "595",
        0
      ]
    },
    "class_type": "Latent Upscale by Factor (WAS)",
    "_meta": {
      "title": "Latent Upscale by Factor (WAS)"
    }
  },
  "616": {
    "inputs": {
      "lora_name": "Flux\\Test_real_photo_Flux.safetensors",
      "strength_model": 1,
      "strength_clip": 1,
      "model": [
        "629",
        0
      ],
      "clip": [
        "629",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "617": {
    "inputs": {
      "steps": 25,
      "end_at_step": 20,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "normalize": "disable",
      "model": [
        "602",
        0
      ],
      "positive": [
        "601",
        0
      ],
      "negative": [
        "618",
        0
      ],
      "latent_image": [
        "614",
        0
      ]
    },
    "class_type": "BNK_Unsampler",
    "_meta": {
      "title": "Unsampler"
    }
  },
  "618": {
    "inputs": {
      "clip_l": "",
      "t5xxl": "",
      "guidance": 3.5,
      "clip": [
        "616",
        1
      ]
    },
    "class_type": "CLIPTextEncodeFlux",
    "_meta": {
      "title": "Empty Negative"
    }
  },
  "619": {
    "inputs": {
      "ratio": 0.3,
      "samples1": [
        "614",
        0
      ],
      "samples2": [
        "617",
        0
      ]
    },
    "class_type": "LatentInterpolate",
    "_meta": {
      "title": "LatentInterpolate"
    }
  },
  "620": {
    "inputs": {
      "samples": [
        "617",
        0
      ],
      "vae": [
        "592",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "621": {
    "inputs": {
      "images": [
        "620",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "629": {
    "inputs": {
      "lora_name": "Flux\\flux-realism-lora.safetensors",
      "strength_model": 0.6,
      "strength_clip": 1,
      "model": [
        "594",
        0
      ],
      "clip": [
        "593",
        0
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "635": {
    "inputs": {
      "pixels": [
        "288",
        0
      ],
      "vae": [
        "592",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "636": {
    "inputs": {
      "rgthree_comparer": {
        "images": []
      },
      "image_a": [
        "620",
        0
      ],
      "image_b": [
        "613",
        0
      ]
    },
    "class_type": "Image Comparer (rgthree)",
    "_meta": {
      "title": "Image Comparer (rgthree)"
    }
  },
  "637": {
    "inputs": {
      "image": [
        "288",
        0
      ]
    },
    "class_type": "GetImageSize+",
    "_meta": {
      "title": "🔧 Get Image Size"
    }
  }
}